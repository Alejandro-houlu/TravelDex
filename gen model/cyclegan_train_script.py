# -*- coding: utf-8 -*-
"""CycleGan_train_script.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r8_8BnY5cyYriXr6CN-xf8v74BaQaUHd
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/MyDrive/NUS_ISS_IS_Masters/Semester 3 Practice Module 3/CycleGAN Weather Training')
!ls

"""# Training of Cycle Gan model for Sunny2Rainy"""

from PIL import Image
import os

def resize_images(input_dir, output_dir, prefix, size=(256, 256)):
    os.makedirs(output_dir, exist_ok=True)
    # Get list of files and sort them to ensure consistent numbering
    files = sorted(os.listdir(input_dir))
    for i, filename in enumerate(files, start=1):  # Start numbering from 1
        # Open and resize the image
        img = Image.open(os.path.join(input_dir, filename)).resize(size)
        # Convert RGBA to RGB before saving
        img = img.convert('RGB')
        # Create new filename with prefix and number (e.g., sunny_1.jpg)
        new_filename = f"{prefix}_{i}.jpg"
        # Save the image with the new name
        img.save(os.path.join(output_dir, new_filename))

# Resize and rename images for trainA (sunny) and trainB (cloudy/rainy)
resize_images('sunny_vs_rainy/trainA', 'sunny_vs_rainy/train_resized/trainA_resized', prefix='sunny')
resize_images('sunny_vs_rainy/trainB', 'sunny_vs_rainy/train_resized/trainB_resized', prefix='cloudy')

print(f"trainA-Sunny size: {len(os.listdir('sunny_vs_rainy/train_resized/trainA_resized'))}, trainB-Rainy size: {len(os.listdir('sunny_vs_rainy/train_resized/trainB_resized'))}")

!pip install torch torchvision

!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git
!cd pytorch-CycleGAN-and-pix2pix

!pip install -r requirements.txt

!python pytorch-CycleGAN-and-pix2pix/train.py --dataroot ./sunny_vs_rainy/train_resized --name sunny2rainy --model cycle_gan --n_epochs 300 \
--batch_size 16 --verbose --print_freq 10 --save_epoch_freq 10 --save_latest_freq 1000 --checkpoints_dir ./my_checkpoints \
--rotation_degrees 15 --zoom_max 1.3

!python pytorch-CycleGAN-and-pix2pix/test.py --dataroot ./sunny_vs_rainy/test_t --name sunny2rainy --model cycle_gan --num_test 50 --checkpoints_dir ./my_checkpoints --gpu_ids -1

"""# Upscaling generated images

PIL scaling method
"""

from PIL import Image
import os

def upscale_basic(input_dir, output_dir, size=(1024, 1024)):
    os.makedirs(output_dir, exist_ok=True)
    for filename in os.listdir(input_dir):
        img = Image.open(os.path.join(input_dir, filename)).resize(size, Image.BICUBIC)
        img.save(os.path.join(output_dir, filename))

upscale_basic('results/sunny2rainy/test_latest/images', 'results/sunny2rainy/upscaled_basic')

display(img)

"""Real-ERSGAN method (xinntao)"""

!git clone https://github.com/xinntao/Real-ESRGAN.git
!cd Real-ESRGAN

!pip install -r '/content/drive/MyDrive/NUS_ISS_IS_Masters/Semester 3 Practice Module 3/CycleGAN Weather Training/Real-ESRGAN/requirements.txt'

!sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' '/usr/local/lib/python3.11/dist-packages/basicsr/data/degradations.py'

!python Real-ESRGAN/inference_realesrgan.py -n RealESRGAN_x4plus.pth -i "/content/drive/MyDrive/NUS_ISS_IS_Masters/Semester 3 Practice Module 3/CycleGAN Weather Training/results/sunny2rainy/test_latest/test" \
-o '/content/drive/MyDrive/NUS_ISS_IS_Masters/Semester 3 Practice Module 3/CycleGAN Weather Training/results/upscaled_basic' -g -1

"""Real-ERSGAN (sberbank)"""

!pip install git+https://github.com/sberbank-ai/Real-ESRGAN.git
!cd Real-ERSGAN

!pip install huggingface_hub==0.7.0

import torch
from PIL import Image
import numpy as np
from RealESRGAN import RealESRGAN

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = RealESRGAN(device, scale=4)
model.load_weights('/content/drive/MyDrive/NUS_ISS_IS_Masters/Semester 3 Practice Module 3/CycleGAN Weather Training/Real-ERSGAN/weights/RealESRGAN_x4.pth', download=False)

path_to_image = '/content/drive/MyDrive/NUS_ISS_IS_Masters/Semester 3 Practice Module 3/CycleGAN Weather Training/results/sunny2rainy/test_latest/test/mbs_cloudy_2_fake_A.png'
image = Image.open(path_to_image).convert('RGB')

sr_image = model.predict(image)
sr_image.save('results/upscaled_basic')

display(sr_image)

"""D_A: 2.169:
Loss of the discriminator for domain A (sunny images). D_A tries to distinguish real sunny images from fake ones generated by G_B (B→A).

Value: 2.169 is relatively high early in training, as the discriminator is still learning. Ideally, it stabilizes around 0.5 as G_B improves, balancing the adversarial game.

G_A: 2.360:
Loss of the generator G_A (sunny→rainy). This includes:
Adversarial loss (fooling D_B with fake rainy images).

Cycle-consistency loss (part of cycle_A).

Optionally, identity loss (part of idt_A if --lambda_identity > 0).

Value: 2.360 reflects the combined loss. Early in training, it’s high as G_A is still refining its outputs.

cycle_A: 5.122:
Cycle-consistency loss for domain A: Measures how well the cycle A→B→A reconstructs the original sunny image (||G_B(G_A(A)) - A||).

Weighted by --lambda_A (default: 10), so the raw L1 loss is ~0.5122, then multiplied by 10.

Value: 5.122 is reasonable early on but should decrease as training progresses, indicating better reconstruction.

idt_A: 2.607:
Identity loss for domain A: Measures how well G_B preserves sunny images when applied to them directly (||G_B(A) - A||). Only included if --lambda_identity > 0 (default: 0.5).

Weighted by --lambda_identity × --lambda_A (e.g., 0.5 × 10 = 5), so raw loss is ~0.5214.

Value: 2.607 suggests G_B slightly alters sunny images when it shouldn’t, which is expected early in training.

D_B: 1.579:
Loss of the discriminator for domain B (rainy images). D_B distinguishes real rainy images from fake ones generated by G_A (A→B).

Value: 1.579, like D_A, is high initially and should drop toward 0.5 as G_A improves.

G_B: 1.656:
Loss of the generator G_B (rainy→sunny). Combines adversarial loss (fooling D_A), cycle-consistency (part of cycle_B), and identity loss (part of idt_B).

Value: 1.656 is lower than G_A’s loss, possibly indicating G_B is learning faster or domain B is easier to generate.

cycle_B: 4.744:
Cycle-consistency loss for domain B: Measures reconstruction quality for B→A→B (||G_A(G_B(B)) - B||).

Weighted by --lambda_B (default: 10), so raw loss is ~0.4744.

Value: 4.744 is slightly lower than cycle_A, suggesting better reconstruction for rainy→sunny→rainy at this point.

idt_B: 2.507:
Identity loss for domain B: Measures preservation of rainy images by G_A (||G_A(B) - B||).

Weighted by --lambda_identity × --lambda_B (e.g., 0.5 × 10 = 5), so raw loss is ~0.5014.

Value: 2.507 is close to idt_A, indicating similar identity preservation challenges.


"""

